# SoPhie configuration file
# SoPhie model
use_gpu: 1
dataset_name: ethucy
dataset:
    path: data/datasets/zara1
    video: data/datasets/videos
    batch_size: 1 # 16 max
    shuffle: True
    num_workers: 0
sophie:
    generator: 
        # Visual Extractor (CNN)
        visual_extractor:
            type: "vgg19"
            vgg:
                vgg_type: 19
                batch_norm: False
                pretrained: True
                features: True

        # Joint Extractor
        joint_extractor:
            type: "encoder_sort"
            config:
                encoder:
                    num_layers: 1 # Numbers of agents
                    hidden_dim: 32
                    emb_dim: 16 # embedding input from mlp
                    mlp_config:
                        dim_list: [2, 16] # input
                        activation: 'relu'
                        batch_norm: False
                        dropout: 0
                    dropout: 0
        physical_attention:
            linear_decoder:
                in_features: 128
                out_features: 512
            linear_feature:
                in_features: 324 # From 600x600 images to 18x18 (= 324) activation maps
                out_features: 2
            softmax:
                dim: 0
        social_attention:
            linear_decoder:
                in_features: 128
                out_features: 256 # 8 (observations length) x 32 (batch = number of agents)
            linear_feature:
                in_features: 32
                out_features: 2
            softmax:
                dim: 0
        decoder:
            num_layers: 1
            hidden_dim: 128 #&h_dim
            emb_dim: 64
            dropout: 0
            seq_len: 12
            linear_1:
                input_dim: 2
                output_dim: 64
            linear_2:
                input_dim: 128 #*h_dim
                output_dim: 64
            linear_3:
                input_dim: 64 #*h_dim
                output_dim: 32
            mlp_config:
                dim_list: [64, 128, 64, 2] 
                activation: 'relu'
                batch_norm: False
                dropout: 0
            # linear_3:
            #     input_dim: 128 #*h_dim
            #     output_dim: 64
            # linear_4:
            #     input_dim: 64 #*h_dim
            #     output_dim: 2
        noise:
            noise_type: "gauss" # gauss or uniform

    discriminator:
        # Encoder
        encoder:
            num_layers: 1
            hidden_dim: 64
            emb_dim: 16 # Bidimensional points (xy)
            mlp_config:
                dim_list: [2, 16] 
                activation: 'relu'
                batch_norm: False
                dropout: 0
            dropout: 0

        # Classifier
        classifier:
            mlp_config:
                dim_list: [64, 1024, 1] 
                activation: 'relu'
                batch_norm: False
                dropout: 0

hyperparameters:
    g_learning_rate: 5.0e-4
    d_learning_rate: 5.0e-4
    num_iterations: 20000
    num_epochs: 250
    d_steps: 2
    g_steps: 1
    timing: 0 # ?> Waits for all kernels in all streams on a CUDA device to complete.
    print_every: 100
    checkpoint_every: 500
    output_dir: "save"
    checkpoint_name: "test"
    checkpoint_start_from: 
    restore_from_checkpoint: 
    clipping_threshold_d: 0
    clipping_threshold_g: 0
    obs_len: 8
    best_k: 1
    l2_loss_weight: 0
    num_samples_check: 5000
    pred_len: 8