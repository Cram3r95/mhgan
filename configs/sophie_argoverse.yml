# SoPhie configuration file
# SoPhie model
use_gpu: 1
dataset_name: argoverse

dataset:
    # TODO: IMPROVE THIS, NOT CALCULATING THE DATA BEFOREHAND
    joined_obs_trajectories: data/datasets/argoverse/motion-forecasting/train/joined_obs_trajectories.npy
    sequence_separators: data/datasets/argoverse/motion-forecasting/train/sequence_separators.npy

    path: data/datasets/argoverse/motion-forecasting/train
    video: data/datasets/argoverse/motion-forecasting/train
    test_submission: False
    batch_size: 4 # 16 max
    shuffle: True
    num_workers: 0

hyperparameters:
    g_learning_rate: 5.0e-4
    d_learning_rate: 5.0e-4
    num_iterations: 20000
    num_epochs: 250
    d_steps: 2
    g_steps: 1
    timing: 0 # ?> Waits for all kernels in all streams on a CUDA device to complete.
    print_every: 100
    checkpoint_every: 500 # cambiar
    output_dir: "save"
    checkpoint_name: "test"
    checkpoint_start_from: 
    restore_from_checkpoint: 
    clipping_threshold_d: 0
    clipping_threshold_g: 0
    best_k: 1
    l2_loss_weight: 0
    num_samples_check: 5000
    obs_len: 20
    pred_len: 30
    number_agents: &num_agents 10
    hidden_dim_lstm_decoder: &hidden_dim_lstm_decoder 128

sophie:
    generator: 
        # Visual Extractor (CNN)
        visual_extractor:
            type: "vgg19"
            vgg:
                vgg_type: 19
                batch_norm: False
                pretrained: True
                features: True

        # Joint Extractor
        joint_extractor:
            type: "encoder_sort"
            config:
                encoder:
                    num_layers: 1 
                    hidden_dim: *num_agents
                    emb_dim: 16 # embedding input from mlp
                    mlp_config:
                        dim_list: [2, 16] # From 2 (x,y) to 16 (original embedding of the paper)
                        activation: 'relu'
                        batch_norm: False
                        dropout: 0
                    dropout: 0
        physical_attention:
            linear_decoder:
                in_features: *hidden_dim_lstm_decoder # Original paper
                out_features: 512 # Original paper
            linear_feature:
                in_features: 324 # # Original paper. From 600 x 600 images to 18 x 18 ( = 324) activation maps
                out_features: 2
            softmax:
                dim: 0
        social_attention:
            linear_decoder:
                in_features: *hidden_dim_lstm_decoder # Original paper
                out_features: # Past Observations x Number of agents. Fill in the code
            linear_feature:
                in_features: *num_agents 
                out_features: 2
            softmax:
                dim: 0
        decoder:
            linear_1:
                input_dim: *num_agents
                output_dim: 64 # Original paper

            # LSTM

            num_layers: 1
            hidden_dim: *hidden_dim_lstm_decoder
            emb_dim: 64
            dropout: 0
            seq_len: 12

            linear_2:
                input_dim: *hidden_dim_lstm_decoder
                output_dim: 64 # Original paper
            mlp_config:
                dim_list: [64, 128, 64, 2] 
                activation: 'relu'
                batch_norm: False
                dropout: 0
            linear_3: # Not used at this moment (agentscorrector in decoder module)
                input_dim:  
                output_dim: 

        noise:
            noise_type: "gauss" # gauss or uniform

    discriminator:
        # Encoder
        encoder:
            num_layers: 1
            hidden_dim: 64
            emb_dim: 16 # embedding input from mlp
            mlp_config:
                dim_list: [2, 16] # From 2 (x,y) to 16 (original embedding of the paper)
                activation: 'relu'
                batch_norm: False
                dropout: 0
            dropout: 0

        # Classifier
        classifier:
            mlp_config:
                dim_list: [64, 1024, 1] 
                activation: 'relu'
                batch_norm: False
                dropout: 0