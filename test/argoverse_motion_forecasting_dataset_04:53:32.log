Configuration: 
{'use_gpu': 1, 'dataset_name': 'argoverse_motion_forecasting_dataset', 'dataset': {'path': 'data/datasets/argoverse/motion-forecasting/', 'split': 'train', 'batch_size': 8, 'split_percentage': 0.05, 'shuffle': False, 'class_balance': -1.0, 'num_workers': 0}, 'optim_parameters': {'g_learning_rate': 0.0001, 'g_weight_decay': 0, 'd_learning_rate': 0.0001, 'd_weight_decay': 0}, 'hyperparameters': {'output_single_agent': True, 'classic_trainer': False, 'tensorboard_active': True, 'num_iterations': 20000, 'num_epochs': 100, 'd_steps': 2, 'g_steps': 1, 'timing': 0, 'print_every': 2, 'checkpoint_every': 100, 'output_dir': 'test', 'exp_description': 'no normalization, no sigmoid in discriminator, decodettemporal with linear output, social attention for each batch', 'checkpoint_name': '0', 'checkpoint_start_from': None, 'restore_from_checkpoint': None, 'clipping_threshold_d': 0, 'clipping_threshold_g': 1.5, 'best_k': 10, 'l2_loss_weight': 1, 'num_samples_check': 5000, 'obs_len': 20, 'pred_len': 30, 'num_agents_per_obs': 10, 'distance_threshold': 40, 'hidden_dim_lstm_decoder': 128}, 'sophie': {'generator': {'visual_extractor': {'type': 'vgg19', 'vgg': {'vgg_type': 19, 'batch_norm': False, 'pretrained': True, 'features': True}}, 'joint_extractor': {'type': 'encoder_sort', 'config': {'encoder': {'num_layers': 1, 'hidden_dim': 10, 'emb_dim': 16, 'mlp_config': {'dim_list': [2, 16], 'activation': 'relu', 'batch_norm': False, 'dropout': 0}, 'dropout': 0}}}, 'physical_attention': {'linear_decoder': {'in_features': 128, 'out_features': 512}, 'linear_feature': {'in_features': 324, 'out_features': 2}, 'softmax': {'dim': 0}}, 'social_attention': {'linear_decoder': {'in_features': 128, 'out_features': 200}, 'linear_feature': {'in_features': 10, 'out_features': 2}, 'softmax': {'dim': 0}}, 'decoder': {'linear_1': {'input_dim': 10, 'output_dim': 64}, 'num_layers': 1, 'hidden_dim': 128, 'emb_dim': 64, 'dropout': 0, 'pred_len': 30, 'linear_2': {'input_dim': 128, 'output_dim': 64}, 'mlp_config': {'dim_list': [64, 128, 64, 2], 'activation': '', 'batch_norm': True, 'dropout': 0.5}, 'linear_3': {'input_dim': None, 'output_dim': None}}, 'noise': {'noise_type': 'gauss'}}, 'discriminator': {'encoder': {'num_layers': 1, 'hidden_dim': 64, 'emb_dim': 16, 'mlp_config': {'dim_list': [2, 16], 'activation': 'relu', 'batch_norm': True, 'dropout': 0.5}, 'dropout': 0}, 'classifier': {'mlp_config': {'dim_list': [64, 1024, 1], 'activation': 'relu', 'batch_norm': True, 'dropout': 0.5}}}}, 'base_dir': PosixPath('/home/robesafe/tesis/SoPhie')}
Initializing train dataset
Initializing val dataset
abs_norm: (tensor(-22.2594, dtype=torch.float64), tensor(4733.9949, dtype=torch.float64))
abs_norm: (tensor(-17.6174, dtype=torch.float64), tensor(19.1474, dtype=torch.float64))
There are 64356 iterations per epoch
Generator model:
TrajectoryGenerator(
  (visual_feature_extractor): VisualExtractor(
    (module): VGG(
      (module): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (6): ReLU(inplace=True)
        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (8): ReLU(inplace=True)
        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (11): ReLU(inplace=True)
        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (13): ReLU(inplace=True)
        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (15): ReLU(inplace=True)
        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (17): ReLU(inplace=True)
        (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (20): ReLU(inplace=True)
        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (22): ReLU(inplace=True)
        (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (24): ReLU(inplace=True)
        (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (26): ReLU(inplace=True)
        (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (29): ReLU(inplace=True)
        (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (31): ReLU(inplace=True)
        (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (33): ReLU(inplace=True)
        (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (35): ReLU(inplace=True)
        (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
    )
  )
  (encoder): Encoder(
    (encoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (lne): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  (sattn): MultiHeadAttention(
    (attention): DotProductAttention(
      (dropout): Dropout(p=0, inplace=False)
    )
    (W_q): Linear(in_features=32, out_features=32, bias=False)
    (W_k): Linear(in_features=32, out_features=32, bias=False)
    (W_v): Linear(in_features=32, out_features=32, bias=False)
    (W_o): Linear(in_features=32, out_features=32, bias=False)
  )
  (pos_encoding): PositionalEncoding(
    (dropout): Dropout(p=0, inplace=False)
  )
  (pattn): MultiHeadAttention(
    (attention): DotProductAttention(
      (dropout): Dropout(p=0, inplace=False)
    )
    (W_q): Linear(in_features=32, out_features=32, bias=False)
    (W_k): Linear(in_features=18432, out_features=32, bias=False)
    (W_v): Linear(in_features=18432, out_features=32, bias=False)
    (W_o): Linear(in_features=32, out_features=32, bias=False)
  )
  (decoder): DecoderTemporal(
    (decoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=40, out_features=16, bias=True)
    (ln1): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
    (hidden2pos): Linear(in_features=32, out_features=2, bias=True)
    (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (output_activation): Sigmoid()
  )
  (lnc): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  (mlp_decoder_context): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=64, out_features=24, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
  )
)
Discriminator model:
TrajectoryDiscriminator(
  (encoder): Encoder(
    (encoder): LSTM(16, 64)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (real_classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=64, out_features=1, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
  )
)
Train 1288
Val 247
Starting epoch 1
